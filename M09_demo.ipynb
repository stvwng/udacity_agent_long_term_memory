{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6787e5",
   "metadata": {},
   "source": [
    "# Long-term Memory\n",
    "This notebook demonstrates how to take advantage of RAG-like applications to build a memory that is persisted across sessions.\n",
    "\n",
    "## What we'll learn:\n",
    "- Basic ideas of registering and searching memory\n",
    "- Create abstraction to handle long-term memory\n",
    "- Bind long-term memory to your agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b002c2e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdb85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f724f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass, field\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from lib.vector_db import VectorStoreManager\n",
    "from lib.documents import Document, Corpus\n",
    "from lib.agents import Agent\n",
    "from lib.tooling import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3721051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a53070",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a8b08b",
   "metadata": {},
   "source": [
    "## Playing with Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b074d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = VectorStoreManager(OPENAI_API_KEY)\n",
    "vector_store = db.get_or_create_store(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c55506",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\n",
    "    Document(\n",
    "        content= \"I prefer Nintendo games\", \n",
    "        metadata = {\n",
    "            \"user_id\": \"1\", \n",
    "            \"session_id\": \"games\",\n",
    "            \"timestamp\": datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"),\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3c79064",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\n",
    "    Corpus([\n",
    "        Document(\n",
    "            content= \"I prefer Sony games\", \n",
    "            metadata = {\n",
    "                \"user_id\": \"2\", \n",
    "                \"session_id\": \"games\",\n",
    "                \"timestamp\": datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"),\n",
    "            },\n",
    "        ),\n",
    "        Document(\n",
    "            content= \"I have an Electric Car\", \n",
    "            metadata = {\n",
    "                \"user_id\": \"2\", \n",
    "                \"session_id\": \"vehicles\",\n",
    "                \"timestamp\": datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"),\n",
    "            },\n",
    "        )\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df51e872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['04cee36b-093a-4bab-923b-15c4e30de250']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['I prefer Sony games']],\n",
       " 'uris': None,\n",
       " 'included': ['documents', 'distances', 'metadatas'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'session_id': 'games',\n",
       "    'timestamp': '06-22-2025 23:22:51',\n",
       "    'user_id': '2'}]],\n",
       " 'distances': [[0.3349607586860657]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.query(\n",
    "    query_texts=[\"game preference\"],\n",
    "    n_results=1,\n",
    "    where={\"user_id\": \"2\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b7b43",
   "metadata": {},
   "source": [
    "## Useful Abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eca686",
   "metadata": {},
   "source": [
    "- MemoryFragment\n",
    "- MemorySearchResult\n",
    "- TimestampFilter\n",
    "- LongTermMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "414e10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MemoryFragment:\n",
    "    \"\"\"\n",
    "    Represents a single piece of memory information stored in the long-term memory system.\n",
    "    \n",
    "    This class encapsulates user preferences, facts, or contextual information that can be\n",
    "    retrieved later to provide personalized responses in conversational AI applications.\n",
    "    \n",
    "    Attributes:\n",
    "        content (str): The actual memory content or information to be stored\n",
    "        owner (str): Identifier for the user who owns this memory fragment\n",
    "        namespace (str): Logical grouping for organizing related memories (default: \"default\")\n",
    "        timestamp (int): Unix timestamp when the memory was created (auto-generated)\n",
    "    \"\"\"\n",
    "    content: str\n",
    "    owner: str \n",
    "    namespace: str = \"default\"\n",
    "    timestamp: int = field(default_factory=lambda: int(datetime.now().timestamp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeac7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MemorySearchResult:\n",
    "    \"\"\"\n",
    "    Container for the results of a memory search operation.\n",
    "    \n",
    "    Encapsulates both the retrieved memory fragments and associated metadata\n",
    "    such as distance scores from the vector search.\n",
    "    \n",
    "    Attributes:\n",
    "        fragments (List[MemoryFragment]): List of memory fragments matching the search query\n",
    "        metadata (Dict): Additional information about the search results (e.g., distances, scores)\n",
    "    \"\"\"\n",
    "    fragments: List[MemoryFragment]\n",
    "    metadata: Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed82270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TimestampFilter:\n",
    "    \"\"\"\n",
    "    Filter criteria for time-based memory searches.\n",
    "    \n",
    "    Allows filtering memory fragments based on when they were created,\n",
    "    enabling retrieval of recent memories or memories from specific time periods.\n",
    "    \n",
    "    Attributes:\n",
    "        greater_than_value (int, optional): Unix timestamp - only return memories created after this time\n",
    "        lower_than_value (int, optional): Unix timestamp - only return memories created before this time\n",
    "    \"\"\"\n",
    "    greater_than_value: int = None\n",
    "    lower_than_value: int = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e2542b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongTermMemory:\n",
    "    \"\"\"\n",
    "    Manages persistent memory storage and retrieval using vector embeddings.\n",
    "    \n",
    "    This class provides a high-level interface for storing and searching user memories,\n",
    "    preferences, and contextual information across conversation sessions. It uses\n",
    "    vector similarity search to find relevant memories based on semantic meaning.\n",
    "    \n",
    "    The memory system supports:\n",
    "    - Multi-user memory isolation\n",
    "    - Namespace-based organization\n",
    "    - Time-based filtering\n",
    "    - Semantic similarity search\n",
    "    \"\"\"\n",
    "    def __init__(self, db:VectorStoreManager):\n",
    "        self.vector_store = db.create_store(\"long_term_memory\", force=True)\n",
    "\n",
    "    def get_namespaces(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve all unique namespaces currently stored in memory.\n",
    "        \n",
    "        Useful for understanding how memories are organized and for\n",
    "        administrative purposes.\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: List of unique namespace identifiers\n",
    "        \"\"\"\n",
    "        results = self.vector_store.get()\n",
    "        namespaces = [r[\"metadatas\"][0][\"namespace\"] for r in results]\n",
    "        return namespaces\n",
    "\n",
    "    def register(self, memory_fragment:MemoryFragment, metadata:Optional[Dict[str, str]]=None):\n",
    "        \"\"\"\n",
    "        Store a new memory fragment in the long-term memory system.\n",
    "        \n",
    "        The memory is converted to a vector embedding and stored with associated\n",
    "        metadata for later retrieval. Additional metadata can be provided to\n",
    "        enhance searchability.\n",
    "        \n",
    "        Args:\n",
    "            memory_fragment (MemoryFragment): The memory content to store\n",
    "            metadata (Optional[Dict[str, str]]): Additional metadata to associate with the memory\n",
    "        \"\"\"\n",
    "        complete_metadata = {\n",
    "            \"owner\": memory_fragment.owner,\n",
    "            \"namespace\": memory_fragment.namespace,\n",
    "            \"timestamp\": memory_fragment.timestamp,\n",
    "        }\n",
    "        if metadata:\n",
    "            complete_metadata.update(metadata)\n",
    "\n",
    "        self.vector_store.add(\n",
    "            Document(\n",
    "                content=memory_fragment.content,\n",
    "                metadata=complete_metadata,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def search(self, query_text:str, owner:str, limit:int=3,\n",
    "               timestamp_filter:Optional[TimestampFilter]=None, \n",
    "               namespace:Optional[str]=\"default\") -> MemorySearchResult:\n",
    "        \"\"\"\n",
    "        Search for relevant memories using semantic similarity.\n",
    "        \n",
    "        Performs a vector similarity search to find memories that are semantically\n",
    "        related to the query text. Results are filtered by owner, namespace, and\n",
    "        optionally by timestamp range.\n",
    "        \n",
    "        Args:\n",
    "            query_text (str): The search query to find similar memories\n",
    "            owner (str): User identifier to filter memories by ownership\n",
    "            limit (int): Maximum number of results to return (default: 3)\n",
    "            timestamp_filter (Optional[TimestampFilter]): Time-based filtering criteria\n",
    "            namespace (Optional[str]): Namespace to search within (default: \"default\")\n",
    "            \n",
    "        Returns:\n",
    "            MemorySearchResult: Container with matching memory fragments and metadata\n",
    "        \"\"\"\n",
    "\n",
    "        where = {\n",
    "            \"$and\": [\n",
    "                {\n",
    "                    \"namespace\": {\n",
    "                        \"$eq\": namespace\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"owner\": {\n",
    "                        \"$eq\": owner\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        if timestamp_filter:\n",
    "            if timestamp_filter.greater_than_value:\n",
    "                where[\"$and\"].append({\n",
    "                    \"timestamp\": {\n",
    "                        \"$gt\": timestamp_filter.greater_than_value,\n",
    "                    }\n",
    "                })\n",
    "            if timestamp_filter.lower_than_value:\n",
    "                where[\"$and\"].append({\n",
    "                    \"timestamp\": {\n",
    "                        \"$lt\": timestamp_filter.lower_than_value,\n",
    "                    }\n",
    "                })\n",
    "\n",
    "        result = self.vector_store.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=limit,\n",
    "            where=where\n",
    "        )\n",
    "\n",
    "        fragments = []\n",
    "        documents = result.get(\"documents\", [[]])[0]\n",
    "        metadatas = result.get(\"metadatas\", [[]])[0]\n",
    "\n",
    "        for content, meta in zip(documents, metadatas):\n",
    "            owner = meta.get(\"owner\")\n",
    "            namespace = meta.get(\"namespace\", \"default\")\n",
    "            timestamp = meta.get(\"timestamp\")\n",
    "\n",
    "            fragment = MemoryFragment(\n",
    "                content=content,\n",
    "                owner=owner,\n",
    "                namespace=namespace,\n",
    "                timestamp=timestamp\n",
    "            )\n",
    "\n",
    "            fragments.append(fragment)\n",
    "        \n",
    "        result_metadata = {\n",
    "            \"distances\": result.get(\"distances\", [[]])[0]\n",
    "        }\n",
    "\n",
    "        return MemorySearchResult(\n",
    "            fragments=fragments,\n",
    "            metadata=result_metadata\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77a4fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm = LongTermMemory(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffe291cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "past_7d = (now - timedelta(days=7)).timestamp()\n",
    "past_10d = (now - timedelta(days=10)).timestamp()\n",
    "past_14d = (now - timedelta(days=14)).timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f02a5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = [\n",
    "    MemoryFragment(\n",
    "        content=\"I prefer dark mode\", \n",
    "        timestamp=past_7d, \n",
    "        owner=\"Henrique\"\n",
    "    ),\n",
    "    MemoryFragment(\n",
    "        content=\"I have a Nintendo Switch\", \n",
    "        timestamp=past_10d, \n",
    "        owner=\"Henrique\"\n",
    "    ),\n",
    "    MemoryFragment(\n",
    "        content=\"I drove an electric car yesterday\", \n",
    "        timestamp=past_14d, \n",
    "        owner=\"Henrique\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8614989",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in memories:\n",
    "    ltm.register(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "181d2e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemorySearchResult(fragments=[MemoryFragment(content='I prefer dark mode', owner='Henrique', namespace='default', timestamp=1750040572.504482)], metadata={'distances': [0.37668654322624207]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltm.search(\n",
    "    query_text=\"What are my ligthing preferences?\",\n",
    "    owner=\"Henrique\",\n",
    "    limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7d2b9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MemoryFragment(content='I have a Nintendo Switch', owner='Henrique', namespace='default', timestamp=1749781372.504482)]\n",
      "{'distances': [0.5204347372055054]}\n"
     ]
    }
   ],
   "source": [
    "result = ltm.search(\n",
    "    query_text=\" \",\n",
    "    owner=\"Henrique\",\n",
    "    timestamp_filter=TimestampFilter(\n",
    "        greater_than_value=past_14d,\n",
    "        lower_than_value=past_7d\n",
    "    ),\n",
    "    limit=5,\n",
    ")\n",
    "print(result.fragments)\n",
    "print(result.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d43bc",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e804477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_memory_registration_tool(ltm:LongTermMemory, owner:str, namespace:str):\n",
    "    \"\"\"\n",
    "    Create a tool for agents to register new memories.\n",
    "    \n",
    "    This factory function creates a tool that allows AI agents to store new\n",
    "    information about users in the long-term memory system. The tool is\n",
    "    pre-configured with specific owner and namespace parameters.\n",
    "    \n",
    "    Args:\n",
    "        ltm (LongTermMemory): The memory system instance to use\n",
    "        owner (str): User identifier for memory ownership\n",
    "        namespace (str): Namespace for organizing memories\n",
    "        \n",
    "    Returns:\n",
    "        Tool: A configured tool for memory registration\n",
    "    \"\"\"\n",
    "    def _register(content:str):\n",
    "        ltm.register(\n",
    "            MemoryFragment(\n",
    "                content=content, \n",
    "                owner=owner,\n",
    "                namespace=namespace\n",
    "            )\n",
    "        )\n",
    "        return \"Saved new memory\"\n",
    "\n",
    "    return Tool(\n",
    "        func=_register, \n",
    "        name=\"register_memory\", \n",
    "        description=(\n",
    "            \"Register a new memory or preference about the user, \" \n",
    "            \"so it can be useful later as context.\\n\"\n",
    "            \"Args:\\n\"\n",
    "            \"    content: The information to save\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a361ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_memory_search_tool(ltm:LongTermMemory, owner:str, namespace:str):\n",
    "    \"\"\"\n",
    "    Create a tool for agents to search existing memories.\n",
    "    \n",
    "    This factory function creates a tool that allows AI agents to retrieve\n",
    "    relevant memories from the long-term memory system based on semantic\n",
    "    similarity to a search query.\n",
    "    \n",
    "    Args:\n",
    "        ltm (LongTermMemory): The memory system instance to use\n",
    "        owner (str): User identifier for memory ownership\n",
    "        namespace (str): Namespace to search within\n",
    "        \n",
    "    Returns:\n",
    "        Tool: A configured tool for memory search\n",
    "    \"\"\"\n",
    "    def _search(content:str):\n",
    "        result = ltm.search(\n",
    "            query_text=content,\n",
    "            owner=owner,\n",
    "            namespace=namespace,\n",
    "            limit=3,\n",
    "        )\n",
    "        return str(tuple(zip(result.fragments, result.metadata['distances'])))\n",
    "\n",
    "    return Tool(\n",
    "        func=_search, \n",
    "        name=\"search_memory\", \n",
    "        description=(\n",
    "            \"Search for a stored memory or preference about the user, \" \n",
    "            \"so it's useful as a context.\\n\"\n",
    "            \"Args:\\n\"\n",
    "            \"    content: The information to look for\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13f2c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm = LongTermMemory(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98a43e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    tools=[\n",
    "        build_memory_registration_tool(ltm, \"Henrique\", \"conversation\"),\n",
    "        build_memory_search_tool(ltm, \"Henrique\", \"conversation\")\n",
    "    ],\n",
    "    instructions=(\n",
    "        \"You are a helpful assistant. Try to use memory if needed. \" \n",
    "        \"And if the user shares a preference, use your tools to register memories.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdd371b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    query=\"I prefer dark mode\",\n",
    "    session_id=\"session_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e0d125a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_query': 'I prefer dark mode',\n",
       " 'instructions': 'You are a helpful assistant. Try to use memory if needed. And if the user shares a preference, use your tools to register memories.',\n",
       " 'messages': [SystemMessage(role='system', content='You are a helpful assistant. Try to use memory if needed. And if the user shares a preference, use your tools to register memories.'),\n",
       "  UserMessage(role='user', content='I prefer dark mode'),\n",
       "  AIMessage(role='assistant', content=None, tool_calls=[ChatCompletionMessageToolCall(id='call_vkL7gPEh6a8509kcX0rloOgG', function=Function(arguments='{\"content\":\"User prefers dark mode.\"}', name='register_memory'), type='function')]),\n",
       "  ToolMessage(role='tool', content='\"Saved new memory\"', tool_call_id='call_vkL7gPEh6a8509kcX0rloOgG', name='register_memory'),\n",
       "  AIMessage(role='assistant', content=\"I've noted that you prefer dark mode! If there's anything else you'd like to share or if you have more preferences, feel free to let me know.\", tool_calls=None)],\n",
       " 'current_tool_calls': None,\n",
       " 'session_id': 'session_1'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_final_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01fa35c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    query=\"What are my lighting preferences?\",\n",
    "    session_id=\"session_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77c9410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_query': 'What are my lighting preferences?',\n",
       " 'instructions': 'You are a helpful assistant. Try to use memory if needed. And if the user shares a preference, use your tools to register memories.',\n",
       " 'messages': [SystemMessage(role='system', content='You are a helpful assistant. Try to use memory if needed. And if the user shares a preference, use your tools to register memories.'),\n",
       "  UserMessage(role='user', content='What are my lighting preferences?'),\n",
       "  AIMessage(role='assistant', content=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Bd4Hd3bJhI8zHkQ1x7PlOAAf', function=Function(arguments='{\"content\":\"lighting preferences\"}', name='search_memory'), type='function')]),\n",
       "  ToolMessage(role='tool', content='\"((MemoryFragment(content=\\'User prefers dark mode.\\', owner=\\'Henrique\\', namespace=\\'conversation\\', timestamp=1750645374), 0.32105663418769836),)\"', tool_call_id='call_Bd4Hd3bJhI8zHkQ1x7PlOAAf', name='search_memory'),\n",
       "  AIMessage(role='assistant', content=\"Your lighting preference is for dark mode. If you have any other specific preferences or if you'd like to add more details, feel free to share!\", tool_calls=None)],\n",
       " 'current_tool_calls': None,\n",
       " 'session_id': 'session_2'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_final_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa512e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0 (main, Dec  3 2024, 02:24:14) [GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
